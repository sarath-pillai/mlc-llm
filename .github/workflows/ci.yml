name: MLC CI

on:
  push:
    branches:
      - master
    tags:
      - 'v*'
  pull_request:
    branches:
      - master

permissions:
  contents: write
  packages: write

 
jobs:
  test:
    name: Run Unit Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout source
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install required Python packages
        run: |
          pip install pytest
          pip install torch --index-url https://download.pytorch.org/whl/cpu
          pip install --pre -U -f https://mlc.ai/wheels mlc-ai-nightly-cpu mlc-llm-nightly-cpu

      - name: Run unittest script
        run: bash ci/task/test_unittest.sh

  docker:
    name: Docker Build & Publish to GHCR
    needs: [test]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout source (with submodules)
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract Docker metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository_owner }}/mlc-llm
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=sha,format=short
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILDKIT_INLINE_CACHE=1

  build-mlc-llm:
    name: Build MLC-LLM (${{ matrix.os }})
    needs: [test]
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest]

    env:
      BUILD_TYPE: RelWithDebInfo
      ENABLE_CUDA: OFF
      ENABLE_VULKAN: OFF
      ENABLE_METAL: OFF
      ENABLE_OPENCL: OFF
      ENABLE_FLASHINFER: OFF
      CUDA_ARCH: 80

    steps:
      - name: Checkout source
        uses: actions/checkout@v4
        with:
          submodules: recursive


      - name: Install dependencies (Linux)
        if: matrix.os == 'ubuntu-latest'
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential \
            cmake \
            ninja-build \
            libopenblas-dev \
            libgl1-mesa-dev \
            libvulkan-dev \
            ocl-icd-opencl-dev \
            opencl-headers \
            zlib1g-dev \
            libxml2-dev \
            libtinfo-dev \
            libffi-dev \
            libedit-dev \
            libssl-dev \
            python3-dev \
            python3-pip

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Set up Python environment
        run: |
          python -m venv venv
          echo "VENV_PATH=$(pwd)/venv" >> $GITHUB_ENV

      - name: Install Python packages
        run: |
          ${{ runner.os == 'Windows' && '.\\venv\\Scripts\\activate' || 'source ./venv/bin/activate' }}
          pip install --upgrade pip
          pip install setuptools wheel
          pip install torch --index-url https://download.pytorch.org/whl/cpu
          pip install --pre -U -f https://mlc.ai/wheels mlc-ai-nightly-cpu

        shell: bash

      - name: Generate config.cmake
        run: |
          mkdir -p build
          install_prefix="${{ github.workspace }}/install"
          if [[ "$RUNNER_OS" == "Windows" ]]; then
            install_prefix=$(echo "$install_prefix" | sed 's|\\|/|g')
          fi
          cat <<EOF > build/config.cmake
          set(TVM_SOURCE_DIR 3rdparty/tvm)
          set(CMAKE_BUILD_TYPE $BUILD_TYPE)
          set(CMAKE_INSTALL_PREFIX ${install_prefix})
          set(USE_CUDA $ENABLE_CUDA)
          set(USE_VULKAN $ENABLE_VULKAN)
          set(USE_METAL $ENABLE_METAL)
          set(USE_OPENCL $ENABLE_OPENCL)
          set(USE_FLASHINFER $ENABLE_FLASHINFER)
          EOF

          if [ "$ENABLE_FLASHINFER" = "ON" ]; then
            echo "set(FLASHINFER_CUDA_ARCHITECTURES $CUDA_ARCH)" >> build/config.cmake
            echo "set(CMAKE_CUDA_ARCHITECTURES $CUDA_ARCH)" >> build/config.cmake
          fi
        shell: bash

      - name: Cache CMake build
        uses: actions/cache@v4
        with:
          path: |
            build
            ${{ github.workspace }}/install
          key: ${{ runner.os }}-mlc-cmake-${{ hashFiles('**/CMakeLists.txt', '**/config.cmake') }}
          restore-keys: |
            ${{ runner.os }}-mlc-cmake-

      - name: Configure and build
        run: |
          mkdir -p build
          cd build
          cmake -DCMAKE_BUILD_TYPE=$BUILD_TYPE \
                -DCMAKE_INSTALL_PREFIX=${{ github.workspace }}/install \
                -DUSE_CUDA=$ENABLE_CUDA \
                -DUSE_VULKAN=$ENABLE_VULKAN \
                -DUSE_METAL=$ENABLE_METAL \
                -DUSE_OPENCL=$ENABLE_OPENCL \
                -DUSE_FLASHINFER=$ENABLE_FLASHINFER \
                ..
          cmake --build . --parallel
        shell: bash

      - name: Build Python wheel
        run: |
          ${{ runner.os == 'Windows' && '.\\venv\\Scripts\\activate' || 'source ./venv/bin/activate' }}
          cd python
          python setup.py bdist_wheel
        shell: bash

      - name: Upload wheel to GitHub Release
        if: startsWith(github.ref, 'refs/tags/')
        uses: softprops/action-gh-release@v2
        with:
          files: python/dist/*.whl
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

